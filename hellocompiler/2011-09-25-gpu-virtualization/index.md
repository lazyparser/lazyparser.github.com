---
title: "[笔记]Transparent Virtualization of Graphics Processing Units"
date: "2011-09-25"
categories: 
  - "research"
tags: 
  - "anl"
  - "gpu"
  - "opencl"
  - "virtualization"
---

一个月之前 Dr. Pavan Balaji 做的一个报告，介绍他正在做的GPU虚拟化的工作。（[报告的介绍在这里](http://www.is.cas.cn/xwzx/xshd/201108/t20110819_3324600.html)）

问题的背景是目前使用GPU进行计算的案例越来越多，工作站一般使用一块或者几块显卡，高性能中心使用数量巨大的GPU进行加速计算。如果遇到显卡坏了需要更换，或者添加了新的显卡的时候，就需要将应用停止下来，然后重新开始。进一步的，如果应用所在的主机上没有特定的显卡，那么应用就无法进行计算了（或者使用模拟的方法，但是效率很低）。

Dr. Pavan Balaji 给出的解决方法是将GPU虚拟化，做成一个“GPU云服务”的形式（又是云计算）。通过一个运行时环境，将一个网络中的可用的GPU都集中起来管理，统一分配和调度，能够解决上述的两个问题。对于物理显卡维护的问题，云服务环境可以将分配在待拆卸显卡上的计算分流到别的GPU上去；当有新的GPU插进来时再自动的分配计算。如果本机没有可用的GPU，就通过网络将计算发给另外一台或多台主机的闲置GPU上进行计算。

这个方案最大的好处就是方便，但是要应用起来，第一个问题就是通用性。如果重新设计了一套GPU接口，需要程序修改之后才能使用，推广难度就会很大。而最大的挑战是性能。因为在CPU和GPU之间多添加了一个虚拟化层，甚至有时候需要通过网络传送数据，overhead 是相当可观的。

Balaji 重用了 OpenCL 的接口规范，重新实现了 OpenCL 的 runtime，从而解决了第一个问题。使用 OpenCL 接口的程序可以不需要任何修改就运行在虚拟化的GPU上。性能问题，Balaji做的工作主要是在函数的通信优化上，通过缓存函数参数、将小函数调用打包成一个大的数据包再发送等方法降低开销。对于local（本机上）的GPU，这个方法得到的效果还不错。而对于remote（别的主机上）的GPU，使用MPI作为下层实现，数据甩来甩去，优化的效果估计不会太乐观，空间估计也不会太大。
